{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import torch\n",
    "from isegm.model.modeling.segformer import MixVisionTransformer, SegformerHead"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "Pretrained_B2_C = '/playpen-raid/qinliu/projects/ritm_interactive_segmentation/weights/pretrained/mit_b2_converted.pth'\n",
    "\n",
    "backbone_params = dict(\n",
    "    in_channels=6,\n",
    "    embed_dims=64,\n",
    "    num_stages=4,\n",
    "    num_layers=[3, 4, 6, 3],\n",
    "    num_heads=[1, 2, 5, 8],\n",
    "    patch_sizes=[7, 3, 3, 3],\n",
    "    strides=[2, 2, 2, 2],\n",
    "    sr_ratios=[8, 4, 2, 1],\n",
    "    out_indices=(0, 1, 2, 3),\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=True,\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    drop_path_rate=0.1,\n",
    "    pretrained=Pretrained_B2_C\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "backbone = MixVisionTransformer(**backbone_params)\n",
    "# backbone.init_weights()\n",
    "state_dict = torch.load(Pretrained_B2_C)\n",
    "# print(state_dict.keys())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# remove keys\n",
    "# state_dict.pop('layers.0.0.projection.weight')\n",
    "ori_proj_weight = state_dict['layers.0.0.projection.weight']\n",
    "state_dict['layers.0.0.projection.weight'] = torch.cat([ori_proj_weight, ori_proj_weight], dim=1)\n",
    "\n",
    "\n",
    "backbone.load_state_dict(state_dict, True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "backbone.load_state_dict(state_dict, True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "state_dict = torch.load(Pretrained_B2_C)\n",
    "print(state_dict.keys())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "odict_keys(['layers.0.0.projection.weight', 'layers.0.0.projection.bias', 'layers.0.0.norm.weight', 'layers.0.0.norm.bias', 'layers.1.0.projection.weight', 'layers.1.0.projection.bias', 'layers.1.0.norm.weight', 'layers.1.0.norm.bias', 'layers.2.0.projection.weight', 'layers.2.0.projection.bias', 'layers.2.0.norm.weight', 'layers.2.0.norm.bias', 'layers.3.0.projection.weight', 'layers.3.0.projection.bias', 'layers.3.0.norm.weight', 'layers.3.0.norm.bias', 'layers.0.1.0.norm1.weight', 'layers.0.1.0.norm1.bias', 'layers.0.1.0.attn.attn.in_proj_weight', 'layers.0.1.0.attn.attn.in_proj_bias', 'layers.0.1.0.attn.attn.out_proj.weight', 'layers.0.1.0.attn.attn.out_proj.bias', 'layers.0.1.0.attn.sr.weight', 'layers.0.1.0.attn.sr.bias', 'layers.0.1.0.attn.norm.weight', 'layers.0.1.0.attn.norm.bias', 'layers.0.1.0.norm2.weight', 'layers.0.1.0.norm2.bias', 'layers.0.1.0.ffn.layers.0.weight', 'layers.0.1.0.ffn.layers.0.bias', 'layers.0.1.0.ffn.layers.1.weight', 'layers.0.1.0.ffn.layers.1.bias', 'layers.0.1.0.ffn.layers.4.weight', 'layers.0.1.0.ffn.layers.4.bias', 'layers.0.1.1.norm1.weight', 'layers.0.1.1.norm1.bias', 'layers.0.1.1.attn.attn.in_proj_weight', 'layers.0.1.1.attn.attn.in_proj_bias', 'layers.0.1.1.attn.attn.out_proj.weight', 'layers.0.1.1.attn.attn.out_proj.bias', 'layers.0.1.1.attn.sr.weight', 'layers.0.1.1.attn.sr.bias', 'layers.0.1.1.attn.norm.weight', 'layers.0.1.1.attn.norm.bias', 'layers.0.1.1.norm2.weight', 'layers.0.1.1.norm2.bias', 'layers.0.1.1.ffn.layers.0.weight', 'layers.0.1.1.ffn.layers.0.bias', 'layers.0.1.1.ffn.layers.1.weight', 'layers.0.1.1.ffn.layers.1.bias', 'layers.0.1.1.ffn.layers.4.weight', 'layers.0.1.1.ffn.layers.4.bias', 'layers.0.1.2.norm1.weight', 'layers.0.1.2.norm1.bias', 'layers.0.1.2.attn.attn.in_proj_weight', 'layers.0.1.2.attn.attn.in_proj_bias', 'layers.0.1.2.attn.attn.out_proj.weight', 'layers.0.1.2.attn.attn.out_proj.bias', 'layers.0.1.2.attn.sr.weight', 'layers.0.1.2.attn.sr.bias', 'layers.0.1.2.attn.norm.weight', 'layers.0.1.2.attn.norm.bias', 'layers.0.1.2.norm2.weight', 'layers.0.1.2.norm2.bias', 'layers.0.1.2.ffn.layers.0.weight', 'layers.0.1.2.ffn.layers.0.bias', 'layers.0.1.2.ffn.layers.1.weight', 'layers.0.1.2.ffn.layers.1.bias', 'layers.0.1.2.ffn.layers.4.weight', 'layers.0.1.2.ffn.layers.4.bias', 'layers.0.2.weight', 'layers.0.2.bias', 'layers.1.1.0.norm1.weight', 'layers.1.1.0.norm1.bias', 'layers.1.1.0.attn.attn.in_proj_weight', 'layers.1.1.0.attn.attn.in_proj_bias', 'layers.1.1.0.attn.attn.out_proj.weight', 'layers.1.1.0.attn.attn.out_proj.bias', 'layers.1.1.0.attn.sr.weight', 'layers.1.1.0.attn.sr.bias', 'layers.1.1.0.attn.norm.weight', 'layers.1.1.0.attn.norm.bias', 'layers.1.1.0.norm2.weight', 'layers.1.1.0.norm2.bias', 'layers.1.1.0.ffn.layers.0.weight', 'layers.1.1.0.ffn.layers.0.bias', 'layers.1.1.0.ffn.layers.1.weight', 'layers.1.1.0.ffn.layers.1.bias', 'layers.1.1.0.ffn.layers.4.weight', 'layers.1.1.0.ffn.layers.4.bias', 'layers.1.1.1.norm1.weight', 'layers.1.1.1.norm1.bias', 'layers.1.1.1.attn.attn.in_proj_weight', 'layers.1.1.1.attn.attn.in_proj_bias', 'layers.1.1.1.attn.attn.out_proj.weight', 'layers.1.1.1.attn.attn.out_proj.bias', 'layers.1.1.1.attn.sr.weight', 'layers.1.1.1.attn.sr.bias', 'layers.1.1.1.attn.norm.weight', 'layers.1.1.1.attn.norm.bias', 'layers.1.1.1.norm2.weight', 'layers.1.1.1.norm2.bias', 'layers.1.1.1.ffn.layers.0.weight', 'layers.1.1.1.ffn.layers.0.bias', 'layers.1.1.1.ffn.layers.1.weight', 'layers.1.1.1.ffn.layers.1.bias', 'layers.1.1.1.ffn.layers.4.weight', 'layers.1.1.1.ffn.layers.4.bias', 'layers.1.1.2.norm1.weight', 'layers.1.1.2.norm1.bias', 'layers.1.1.2.attn.attn.in_proj_weight', 'layers.1.1.2.attn.attn.in_proj_bias', 'layers.1.1.2.attn.attn.out_proj.weight', 'layers.1.1.2.attn.attn.out_proj.bias', 'layers.1.1.2.attn.sr.weight', 'layers.1.1.2.attn.sr.bias', 'layers.1.1.2.attn.norm.weight', 'layers.1.1.2.attn.norm.bias', 'layers.1.1.2.norm2.weight', 'layers.1.1.2.norm2.bias', 'layers.1.1.2.ffn.layers.0.weight', 'layers.1.1.2.ffn.layers.0.bias', 'layers.1.1.2.ffn.layers.1.weight', 'layers.1.1.2.ffn.layers.1.bias', 'layers.1.1.2.ffn.layers.4.weight', 'layers.1.1.2.ffn.layers.4.bias', 'layers.1.1.3.norm1.weight', 'layers.1.1.3.norm1.bias', 'layers.1.1.3.attn.attn.in_proj_weight', 'layers.1.1.3.attn.attn.in_proj_bias', 'layers.1.1.3.attn.attn.out_proj.weight', 'layers.1.1.3.attn.attn.out_proj.bias', 'layers.1.1.3.attn.sr.weight', 'layers.1.1.3.attn.sr.bias', 'layers.1.1.3.attn.norm.weight', 'layers.1.1.3.attn.norm.bias', 'layers.1.1.3.norm2.weight', 'layers.1.1.3.norm2.bias', 'layers.1.1.3.ffn.layers.0.weight', 'layers.1.1.3.ffn.layers.0.bias', 'layers.1.1.3.ffn.layers.1.weight', 'layers.1.1.3.ffn.layers.1.bias', 'layers.1.1.3.ffn.layers.4.weight', 'layers.1.1.3.ffn.layers.4.bias', 'layers.1.2.weight', 'layers.1.2.bias', 'layers.2.1.0.norm1.weight', 'layers.2.1.0.norm1.bias', 'layers.2.1.0.attn.attn.in_proj_weight', 'layers.2.1.0.attn.attn.in_proj_bias', 'layers.2.1.0.attn.attn.out_proj.weight', 'layers.2.1.0.attn.attn.out_proj.bias', 'layers.2.1.0.attn.sr.weight', 'layers.2.1.0.attn.sr.bias', 'layers.2.1.0.attn.norm.weight', 'layers.2.1.0.attn.norm.bias', 'layers.2.1.0.norm2.weight', 'layers.2.1.0.norm2.bias', 'layers.2.1.0.ffn.layers.0.weight', 'layers.2.1.0.ffn.layers.0.bias', 'layers.2.1.0.ffn.layers.1.weight', 'layers.2.1.0.ffn.layers.1.bias', 'layers.2.1.0.ffn.layers.4.weight', 'layers.2.1.0.ffn.layers.4.bias', 'layers.2.1.1.norm1.weight', 'layers.2.1.1.norm1.bias', 'layers.2.1.1.attn.attn.in_proj_weight', 'layers.2.1.1.attn.attn.in_proj_bias', 'layers.2.1.1.attn.attn.out_proj.weight', 'layers.2.1.1.attn.attn.out_proj.bias', 'layers.2.1.1.attn.sr.weight', 'layers.2.1.1.attn.sr.bias', 'layers.2.1.1.attn.norm.weight', 'layers.2.1.1.attn.norm.bias', 'layers.2.1.1.norm2.weight', 'layers.2.1.1.norm2.bias', 'layers.2.1.1.ffn.layers.0.weight', 'layers.2.1.1.ffn.layers.0.bias', 'layers.2.1.1.ffn.layers.1.weight', 'layers.2.1.1.ffn.layers.1.bias', 'layers.2.1.1.ffn.layers.4.weight', 'layers.2.1.1.ffn.layers.4.bias', 'layers.2.1.2.norm1.weight', 'layers.2.1.2.norm1.bias', 'layers.2.1.2.attn.attn.in_proj_weight', 'layers.2.1.2.attn.attn.in_proj_bias', 'layers.2.1.2.attn.attn.out_proj.weight', 'layers.2.1.2.attn.attn.out_proj.bias', 'layers.2.1.2.attn.sr.weight', 'layers.2.1.2.attn.sr.bias', 'layers.2.1.2.attn.norm.weight', 'layers.2.1.2.attn.norm.bias', 'layers.2.1.2.norm2.weight', 'layers.2.1.2.norm2.bias', 'layers.2.1.2.ffn.layers.0.weight', 'layers.2.1.2.ffn.layers.0.bias', 'layers.2.1.2.ffn.layers.1.weight', 'layers.2.1.2.ffn.layers.1.bias', 'layers.2.1.2.ffn.layers.4.weight', 'layers.2.1.2.ffn.layers.4.bias', 'layers.2.1.3.norm1.weight', 'layers.2.1.3.norm1.bias', 'layers.2.1.3.attn.attn.in_proj_weight', 'layers.2.1.3.attn.attn.in_proj_bias', 'layers.2.1.3.attn.attn.out_proj.weight', 'layers.2.1.3.attn.attn.out_proj.bias', 'layers.2.1.3.attn.sr.weight', 'layers.2.1.3.attn.sr.bias', 'layers.2.1.3.attn.norm.weight', 'layers.2.1.3.attn.norm.bias', 'layers.2.1.3.norm2.weight', 'layers.2.1.3.norm2.bias', 'layers.2.1.3.ffn.layers.0.weight', 'layers.2.1.3.ffn.layers.0.bias', 'layers.2.1.3.ffn.layers.1.weight', 'layers.2.1.3.ffn.layers.1.bias', 'layers.2.1.3.ffn.layers.4.weight', 'layers.2.1.3.ffn.layers.4.bias', 'layers.2.1.4.norm1.weight', 'layers.2.1.4.norm1.bias', 'layers.2.1.4.attn.attn.in_proj_weight', 'layers.2.1.4.attn.attn.in_proj_bias', 'layers.2.1.4.attn.attn.out_proj.weight', 'layers.2.1.4.attn.attn.out_proj.bias', 'layers.2.1.4.attn.sr.weight', 'layers.2.1.4.attn.sr.bias', 'layers.2.1.4.attn.norm.weight', 'layers.2.1.4.attn.norm.bias', 'layers.2.1.4.norm2.weight', 'layers.2.1.4.norm2.bias', 'layers.2.1.4.ffn.layers.0.weight', 'layers.2.1.4.ffn.layers.0.bias', 'layers.2.1.4.ffn.layers.1.weight', 'layers.2.1.4.ffn.layers.1.bias', 'layers.2.1.4.ffn.layers.4.weight', 'layers.2.1.4.ffn.layers.4.bias', 'layers.2.1.5.norm1.weight', 'layers.2.1.5.norm1.bias', 'layers.2.1.5.attn.attn.in_proj_weight', 'layers.2.1.5.attn.attn.in_proj_bias', 'layers.2.1.5.attn.attn.out_proj.weight', 'layers.2.1.5.attn.attn.out_proj.bias', 'layers.2.1.5.attn.sr.weight', 'layers.2.1.5.attn.sr.bias', 'layers.2.1.5.attn.norm.weight', 'layers.2.1.5.attn.norm.bias', 'layers.2.1.5.norm2.weight', 'layers.2.1.5.norm2.bias', 'layers.2.1.5.ffn.layers.0.weight', 'layers.2.1.5.ffn.layers.0.bias', 'layers.2.1.5.ffn.layers.1.weight', 'layers.2.1.5.ffn.layers.1.bias', 'layers.2.1.5.ffn.layers.4.weight', 'layers.2.1.5.ffn.layers.4.bias', 'layers.2.2.weight', 'layers.2.2.bias', 'layers.3.1.0.norm1.weight', 'layers.3.1.0.norm1.bias', 'layers.3.1.0.attn.attn.in_proj_weight', 'layers.3.1.0.attn.attn.in_proj_bias', 'layers.3.1.0.attn.attn.out_proj.weight', 'layers.3.1.0.attn.attn.out_proj.bias', 'layers.3.1.0.norm2.weight', 'layers.3.1.0.norm2.bias', 'layers.3.1.0.ffn.layers.0.weight', 'layers.3.1.0.ffn.layers.0.bias', 'layers.3.1.0.ffn.layers.1.weight', 'layers.3.1.0.ffn.layers.1.bias', 'layers.3.1.0.ffn.layers.4.weight', 'layers.3.1.0.ffn.layers.4.bias', 'layers.3.1.1.norm1.weight', 'layers.3.1.1.norm1.bias', 'layers.3.1.1.attn.attn.in_proj_weight', 'layers.3.1.1.attn.attn.in_proj_bias', 'layers.3.1.1.attn.attn.out_proj.weight', 'layers.3.1.1.attn.attn.out_proj.bias', 'layers.3.1.1.norm2.weight', 'layers.3.1.1.norm2.bias', 'layers.3.1.1.ffn.layers.0.weight', 'layers.3.1.1.ffn.layers.0.bias', 'layers.3.1.1.ffn.layers.1.weight', 'layers.3.1.1.ffn.layers.1.bias', 'layers.3.1.1.ffn.layers.4.weight', 'layers.3.1.1.ffn.layers.4.bias', 'layers.3.1.2.norm1.weight', 'layers.3.1.2.norm1.bias', 'layers.3.1.2.attn.attn.in_proj_weight', 'layers.3.1.2.attn.attn.in_proj_bias', 'layers.3.1.2.attn.attn.out_proj.weight', 'layers.3.1.2.attn.attn.out_proj.bias', 'layers.3.1.2.norm2.weight', 'layers.3.1.2.norm2.bias', 'layers.3.1.2.ffn.layers.0.weight', 'layers.3.1.2.ffn.layers.0.bias', 'layers.3.1.2.ffn.layers.1.weight', 'layers.3.1.2.ffn.layers.1.bias', 'layers.3.1.2.ffn.layers.4.weight', 'layers.3.1.2.ffn.layers.4.bias', 'layers.3.2.weight', 'layers.3.2.bias'])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from isegm.model.modeling.transformer_helper.cross_entropy_loss import CrossEntropyLoss\n",
    "\n",
    "decode_head_params = dict(\n",
    "    in_channels=[64, 128, 320, 512],\n",
    "    in_index=[0, 1, 2, 3],\n",
    "    channels=256,\n",
    "    dropout_ratio=0.1,\n",
    "    num_classes=1,\n",
    "    loss_decode=CrossEntropyLoss(),\n",
    "    align_corners=False,\n",
    ")\n",
    "\n",
    "head = SegformerHead(**decode_head_params)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "in_shape = (1, 3, 320, 480)\n",
    "input_t = torch.randn(in_shape)\n",
    "\n",
    "additional_shape = (1, 3, 320, 480)\n",
    "additional_t = torch.randn(additional_shape)\n",
    "\n",
    "input_t = torch.cat([input_t, additional_t], dim=1)\n",
    "\n",
    "temp = backbone(input_t)\n",
    "out_t = head(temp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "print(out_t.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 1, 160, 240])\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "d6ef4093ab78b75315b5578de234fc5791126666d11dbc7e5176d4b19b865843"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}